# ✅ activations.hpp — 요약 및 중복 여부

설명 (문서용 한두 줄):

activations.hpp — CUDA/Host 겸용 활성화 함수 모듈.
ReLU, LeakyReLU, GELU, Sigmoid, Tanh 등의 forward/derivative를 템플릿·런타임 양쪽으로 제공한다.

핵심 역할:

ActKind 열거 정의 (프레임워크 전역 기준 enum)

Forward/Backward 활성화 함수 구현 (act_apply, act_deriv, apply_act_runtime, apply_act_grad_runtime)

CUDA + Host 병행 (__device__/__host__ 호환)

중복 가능성:

⚠️ enums.hpp 또는 gemm/detail/api.h 등에서 ActKind가 별도로 정의되어 있다면 충돌 가능.
→ ✅ 권장: activations.hpp의 ActKind만 남기고, 다른 곳은 이 헤더를 include 하도록 통합.

활성함수 구현은 다른 shim 파일들과 기능 중복 없음 (bias, epilogue 등과는 연계만 존재).

요약:

ReLU~Tanh까지의 GPU/Host 활성함수 집합.
ActKind를 전역 기준으로 통일해야 중복 enum 충돌을 방지할 수 있다.

# ✅ ai_capture.hpp — 요약 및 중복 여부

설명 (문서용 한두 줄):

ai_capture.hpp — CUDA Graph 캡처 상태를 감지하고, 캡처 중 금지된 연산(malloc, sync, 등)을 방지하는 안전 가드 유틸리티.

핵심 역할:

CUDA 스트림의 그래프 캡처 상태 조회 (cudaStreamGetCaptureInfo_v2)

캡처 중 호출되면 에러를 반환하는 보호 매크로 (AI_CAPTURE_FORBID_IF_ACTIVE)

상태 열거형(CapturePhase: None / Active / Invalid)

중복 여부:

동일 기능이 다른 파일에 없음.

다만 ai_stream.hpp 와 스트림 핸들 관리 레벨에서 의존 관계 있음 (stream handle type 공유).

ai_memops.hpp 나 ai_tensor.hpp 등에서도 캡처-세이프 체크를 수행한다면,
이 헤더는 그 로직의 공통 하위 모듈로 유지해야 함.

요약:

CUDA Graph 캡처 중 안전성 검증을 담당하는 가드 레이어.
ai_stream.hpp와 함께 사용되어 런타임이 캡처-세이프하게 동작하도록 보장한다.

# ✅ ai_cuda_check.hpp — 요약 및 중복 여부

설명 (문서용 한두 줄):

ai_cuda_check.hpp — CUDA API 호출의 오류를 통합적으로 감지·처리하기 위한 경량 검사 매크로 세트.

핵심 역할:

CUDA 호출 오류 처리 매크로:

AI_CUDA_CHECK(expr) — 즉시 오류 반환 (cudaSuccess 검사)

AI_CUDA_TRY(expr) — CUDA 함수 호출 후 동일 동작

AI_CUDA_CHECK_LAUNCH() — 커널 런치 직후 cudaGetLastError() 검증

반환 타입은 프레임워크 공통 ai::Status 사용 (ai_status.hpp 의존)

중복 여부:

⚠️ ai_status.hpp와 밀접하게 연결된 공용 레벨 유틸.

비슷한 기능이 ai_device.hpp나 ai_memops.hpp 내부에 존재할 수 있으나,
이 헤더는 에러 처리 전용으로 집중된 버전이므로 중복 아님.

gemm/detail/api.h 등에 AI_CUDA_CHECK_LAUNCH와 유사한 매크로가 있다면 이쪽으로 통합 권장.

요약:

CUDA API 호출 오류를 공통 Status 형식으로 반환하는 에러 헨들링 레이어.
런처/커널 단에서 발생하는 예외 상황을 통합적으로 포착한다.

# ✅ ai_defs.hpp — 요약 및 중복 여부

설명 (문서용 한두 줄):

ai_defs.hpp — CUDA 전용 한정자(__host__, __device__, __global__)가 없는 환경에서도 컴파일 가능하도록 정의를 보완하는 호환성 헤더.

핵심 역할:

CUDA 비활성 환경(예: host-only 빌드, CPU 테스트)에서 누락될 수 있는 키워드들을 빈 매크로로 정의.

__CUDACC__ 가 정의되지 않은 경우에도 컴파일이 깨지지 않게 보조.

특히 __forceinline__ 이 CUDA 외부에서 인식되지 않는 문제 방지.

중복 여부:

✅ 다른 shim 파일들과 기능 중복 없음.

다만 activations.hpp 등에서도 유사한 조건부 매크로(AI_RD)를 선언하므로,
이 파일을 공통 상위 포함(기초 헤더) 로 삼으면 중복 제거 가능.
→ 즉, AI_RD 매크로 정의 전 #include "ai_defs.hpp" 로 통일.

요약:

CUDA가 아닌 환경에서도 모든 __host__, __device__ 함수가 안전히 빌드되도록 보장하는 호환성 베이스 헤더.

# ✅ ai_device.hpp — 요약 및 중복 여부

설명 (문서용 한두 줄):

ai_device.hpp — 텐서 장치(Device), 자료형(DType), 레이아웃(Layout) 정의와 안전한 shape 계산 유틸을 제공하는 기본 환경 헤더.

핵심 역할:

전역 공통 enum 정의

Device (CPU / CUDA)

DType (F32, F16, BF16, I32, I8)

Layout (RowMajor / ColMajor)

타입별 크기 계산: dtype_size()

텐서 shape 기반 요소 수 계산: numel_of()

오버플로 방지용 안전 곱셈: safe_mul_nonneg()

중복 여부:

ai_tensor.hpp, tensor_layout.hpp, layout.hpp 등에서도 유사 개념(enum 및 dtype) 을 다룰 가능성이 있음.
→ 중복 포인트:

DType / Layout enum이 별도 파일에서 재정의되면 충돌.

dtype 크기 계산(dtype_size)도 중복될 수 있음.

따라서 이 파일을 장치·자료형 정의의 단일 소스로 두고,
나머지는 여기의 정의를 using 혹은 include 형태로 재사용하는 게 이상적.

요약:

텐서의 장치·데이터형·레이아웃 정의를 표준화하고, 안전한 shape 곱셈 유틸을 제공하는 기본 시스템 헤더.
DType / Layout 정의가 중복되는 다른 파일과 통합 필요.

# ✅ ai_memops.hpp — 요약 & 중복 체크

설명(문서용 한두 줄):

ai_memops.hpp — CUDA memcpy/memset와 malloc/free를 그래프 캡처-세이프로 래핑한 메모리 유틸. 스트림 기반 비동기 호출을 공통 ai::Status로 반환한다.

중복/겹침 포인트:

memcpy_d2d_async와 copy_d2d_async가 기능 중복이다. 하나로 통일 권장(이름만 남기고 다른 쪽은 inline 포워딩).

예) copy_d2d_async(...)만 남기고, memcpy_d2d_async(...)는 return copy_d2d_async(...);로 유지하거나 제거.

에러 체크는 이 파일 내에서 직접 cudaError_t 비교를 수행하므로, ai_cuda_check.hpp의 매크로(AI_CUDA_CHECK/TRY)와 역할이 일부 겹침. 스타일을 하나로 통일하면 좋음.

캡처 가드(AI_CAPTURE_FORBID_IF_ACTIVE)는 ai_capture.hpp에 의존—설계상 OK(중복 아님).

# ai_nvtx.hpp — 요약 & 중복 체크

문서용 한 줄: NVTX 프로파일링 유틸. AI_ENABLE_NVTX 토글로 RAII 범위/마킹(Range, mark)과 매크로(AI_NVTX_RANGE, AI_NVTX_MARK)를 제공하며, 비활성 시 전부 no-op로 동작.

중복 여부: 과거 nvtx.hpp, AI_USE_NVTX/USE_NVTX 매크로와 중복 가능. 본 헤더가 양쪽 플래그를 흡수하므로, NVTX 관련 파일/매크로는 이걸로 단일화하고 NVTX_RANGE/NVTX_MARK만 과거 호환 alias로 유지.

# ✅ ai_ops_base.hpp — 요약 & 중복 여부

설명 (문서용 한두 줄):

ai_ops_base.hpp — 공통 연산(Ops)에서 사용하는 활성화 종류와 GEMM 속성 구조체(GemmAttrs)를 정의한 베이스 헤더.

핵심 역할:

공통 enum ActKind 정의 (ops 전역에서 사용)

GEMM 연산의 속성 패키징 (GemmAttrs):

전치 여부(trans_a, trans_b)

활성화 종류(act)

bias, leaky slope, pre-activation 저장 플래그 등

중복 여부:

⚠️ activations.hpp 및 gemm/detail/api.h에서도 ActKind가 동일한 열거값으로 중복 정의됨.
→ 이 파일을 전역 기준(enum 단일 소스) 으로 하고, 다른 파일에서는 include 형태로 참조하도록 통합해야 함.

GemmAttrs는 현재 독립적이며 중복 없음.

요약:

GEMM과 활성화 관련 공통 메타데이터를 정의하는 핵심 베이스 헤더.
ActKind는 반드시 여기의 정의로 일원화하여 enum 충돌을 방지할 것.

# ✅ ai_shim.hpp — 요약 & 중복 체크

문서용 한두 줄:

ai_shim.hpp — 공통 shim의 집계 헤더. 상태/디바이스/스트림/캡처/메모리/검증/NVTX/ops 메타 + 경량 유틸(enums/layout/workspace)을 한 번에 가져온다.

중복/주의:

무거운 헤더(activations/bias/traits/epilogue_functors 등)는 기본 미포함이므로, 커널에서 필요 시 개별 include 권장(집계에 넣으면 빌드 시간 증가).

ActKind는 여기서 enums.hpp를 통해 단일 소스로 들어오므로, ai_ops_base.hpp나 과거 헤더에서 중복 정의 금지.

# ✅ ai_status.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

ai_status.hpp — 프레임워크 전역의 표준 반환 코드(ai::Status)를 정의하고, 오류 전파 매크로(AI_RETURN_IF_ERROR)를 제공하는 공통 상태 관리 헤더.

핵심 역할:

ai::Status 열거형 정의: 실행 성공/실패/타입 불일치/입출력 누락 등 상세 코드 제공.

오류 전파 매크로 AI_RETURN_IF_ERROR(expr) — 함수 내 일관된 예외 처리 지원.

중복 여부:

✅ 중복 없음.

단, ai_cuda_check.hpp의 AI_CUDA_CHECK 매크로가 이 Status를 반환 타입으로 사용하므로, 이 파일이 항상 선행 포함되어야 함.

요약:

프레임워크의 오류 상태를 통합 관리하는 기본 레이어.
CUDA, Stream, Tensor 등 모든 서브시스템이 공통 Status 타입으로 결과를 반환하도록 표준화한다.

# ✅ ai_stream.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

ai_stream.hpp — CUDA 스트림을 프레임워크 공통 타입(StreamHandle)으로 정의하고, 변환 헬퍼를 제공하는 최소 래퍼.

핵심 역할:

CUDA의 cudaStream_t를 프레임워크 표준 타입명(StreamHandle)으로 통일.

헬퍼 함수 as_cuda_stream() — 내부에서 CUDA API 호출 시 안전하게 캐스팅.

중복 여부:

✅ 다른 파일과 직접적 기능 중복 없음.

ai_capture.hpp, ai_memops.hpp, ai_cuda_check.hpp 등이 이 타입을 참조하므로 핵심 기반 헤더로 유지해야 함.

요약:

CUDA 스트림 타입을 통일하고, 캡처·비동기 연산 등 모든 실행 컨텍스트의 기반이 되는 최소 단위 헤더.

# ✅ ai_tensor.hpp — 요약 & 중복 체크

설명(문서용 한두 줄):

ai_tensor.hpp — CUDA용 비소유 텐서 뷰(Tensor/Descriptor)와 편의 생성·stride/Ld 헬퍼를 제공하는 기본 자료구조.

중복/주의 포인트:

DType, Layout, dtype_size()는 ai_device.hpp가 단일 소스이므로, 이 파일은 그것을 include해서 사용(재정의 금지).

LD/stride 유틸은 이 파일(shim 네임스페이스의 lda/ldb/ldd)에 있고, 유사 기능의 경량 LD 검증은 layout.hpp/tensor_layout.hpp에도 있음 → 역할 분리 유지:

ai_tensor.hpp = 텐서 뷰 + 기본 LD/생성 헬퍼

layout.hpp/tensor_layout.hpp = LD 유효성/추론·검증 로직.

# ✅ ai_validate.hpp — 요약 & 중복 체크

설명(문서용 한두 줄):

ai_validate.hpp — 텐서의 디바이스/레이아웃/랭크/연속성/dtype 등을 표준 ai::Status로 검증하는 공용 밸리데이션 유틸과 NCHW 파싱·axis 정규화 헬퍼를 제공한다.

중복/주의 포인트:

is_cuda_f32_rowmajor()가 tensor_layout.hpp의 Z-버퍼 검증과 부분적으로 겹칠 수 있음. 역할 분리는 그대로 유지:

여기: 검증 API(Status 반환)와 다목적 체크.

tensor_layout.hpp: LD 추론 + Z 버퍼 특정 검증(bool/ldZ 반환).

LD/stride 관련 단순 규칙은 layout.hpp에도 있음(정수 인자 기반). 서로 입력 타입이 다르므로 중복 아님.

이 파일은 ai_status.hpp, ai_tensor.hpp에 의존하므로 항상 먼저 포함되어야 함.

# bias.hpp — 요약 & 중복 체크

한줄 요약: Bias 로딩/합산 유틸. BiasKind에 따라 Scalar/PerM/PerN 바이어스를 CUDA/Host 겸용으로 읽고(load_bias_ptr/load_bias), 누산값에 더한다(add_bias). 1D 텐서 길이로 BiasKind를 추론하는 헬퍼도 포함.

중복 포인트: expected_bias_elems는 이 파일이 단일 소스여야 하며, 다른 곳에 동일 계산이 있으면 제거. Bias 추론(infer_bias_kind_1d_lenMN)은 tensor_layout이 아니라 여기서만 제공하도록 유지.

# ✅ enums.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

enums.hpp — CUDA Shim 전역에서 공용으로 사용하는 연산 열거형(ActKind, BiasKind)을 정의한 최소 ABI 호환 헤더.

핵심 역할:

활성화 함수 종류(ActKind)와 Bias 형태(BiasKind)의 전역 기준(enum class : int) 정의.

모든 ops, kernel, API 구조체에서 동일한 ABI를 보장하기 위한 통합 enum 소스.

중복 여부:

⚠️ 중복 정의 존재:

ai_ops_base.hpp(ActKind), gemm/detail/api.h(ActKind, BiasKind), activations.hpp(ActKind).
→ 이 파일을 단일 소스(enum 중심 헤더) 로 유지하고, 다른 곳은 전부 #include "enums.hpp"로 통일해야 함.

열거값이 완전히 동일하므로 통합 시 ABI 영향 없음.

요약:

ActKind/BiasKind의 유일한 정의를 제공하는 핵심 헤더.
다른 모든 모듈은 이 헤더를 통해 열거형을 공유해야 enum 충돌 및 ABI 불일치를 방지한다.

# epilogue_functors.hpp — 요약 & 중복 체크


한줄 요약: GEMM 에필로그 조립 유틸. α·acc + β·C + bias 계산 후 활성화·(선택)dropout·(선택)Z-stash를 스칼라/벡터 경로로 적용하는 헤더온리 함수 집합.


중복/주의: 활성화(apply_act_runtime)와 Bias 접근(load_bias_ptr)은 각각 activations.hpp, bias.hpp에 의존하므로 이 파일엔 중복 구현 없음. Dropout RNG는 포함하지 않으며, 외부 mask/scale을 주입받는 설계라 다른 RNG 유틸과 충돌 없음.

# ✅ layout.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

layout.hpp — Row-major 2D 텐서의 leading dimension(ld) 유효성 검사와 기본값 해석(resolve_ld)을 제공하는 경량 헬퍼.

핵심 역할:

valid_ld_rowmajor() — 행·열·ld 조합의 합리성 검증 (ld >= cols or 0이면 기본값 허용).

resolve_ld() — ld==0일 때 안전한 기본 fallback 반환.

중복 여부:

⚠️ 동일 시그니처 함수가 gemm/detail/api.h에도 존재하므로,
이 파일(layout.hpp)을 공용 단일 소스로 두고 detail 쪽 구현은 제거 또는 include 형태로 통합하는 것이 권장됨.

요약:

Row-major 행렬의 LD 검증/보정용 표준 유틸.
기존 GEMM API 내부 구현 중복을 제거하고 모든 모듈에서 공통 참조해야 함.

# ✅ numeric.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

numeric.hpp — 정수 범위 검증용 경량 유틸. 64비트 값을 안전하게 int32로 캐스팅 가능한지 확인한다.

핵심 역할:

fits_int32() — int64_t → int32_t 캐스팅이 안전한지 검사 (0 ≤ x ≤ INT_MAX).

오버플로/언더플로 방지를 위한 기본 범위 체크 함수.

중복 여부:

동일 함수가 gemm/detail/gemm_common.hpp에도 있음.
→ ⚠️ 이 파일(numeric.hpp)을 단일 소스로 유지하고, detail 구현은 제거하거나 이 파일을 include하도록 리팩토링 권장.

요약:

정수 캐스팅 안전성을 보장하기 위한 공통 수치 유틸.
기존 GEMM detail 내 범위 검사 코드와 기능 중복 가능성이 있으므로 중앙화 필요.

# ✅ tensor_layout.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

tensor_layout.hpp — Row-Major 텐서의 stride 기반 LD 추론과 Z-버퍼 유효성 검증을 담당하는 헬퍼.

핵심 역할:

infer_ld_rowmajor_2d() — 텐서 stride[0] 기준으로 LD 계산 (stride 정보가 없으면 N 사용).

validate_z_buffer() — CUDA·RowMajor·F32·2D·(M,N) 일치 여부와 LD 범위 검사 수행, ldZ 결과 반환.

중복 여부:

infer_ld_rowmajor_2d() 및 validate_z_buffer()는 기존 gemm_common.hpp의 동명 함수와 완전 동일 기능.
→ ⚠️ tensor_layout.hpp를 표준 단일 소스로 유지하고, detail 쪽 구현은 이 파일을 include하도록 리팩토링 권장.

is_cuda_f32_rowmajor()는 ai_validate.hpp에도 존재하지만 반환 타입(bool vs Status)이 달라 역할 분리 유지 가능.

요약:

Row-Major 텐서의 stride→LD 추론과 Z-버퍼 검증을 전담하는 레이아웃 유틸.
gemm_common의 중복 코드를 제거하고, 모든 모듈이 이 파일을 통해 참조하도록 일원화 필요.

# traits.hpp — 요약 & 중복 체크

한줄 요약: 에필로그 정책 템플릿. BiasMode/to_bias_mode와 Epilogue<AK,BM,HasC,SaveZ>로 α·acc + β·C + bias → (Z stash) → act를 컴파일타임 분기로 최적화한다.

중복 포인트: ActKind/BiasKind는 enums.hpp를 단일 소스로 사용(이 파일은 의존만). 활성화/바이어스 로직 구현은 activations.hpp/bias.hpp에 있으므로 중복 없음; 과거 gemm/detail/traits.hpp가 있다면 삭제/포워딩 필요.

# ✅ workspace.hpp — 요약 & 중복 체크

설명 (문서용 한두 줄):

workspace.hpp — GPU 워크스페이스 메모리의 정렬 상태를 검사하는 간단한 헬퍼. 기본 정렬 단위는 256 bytes.

핵심 역할:

is_workspace_aligned(void* p, size_t alignment=256)
→ 포인터 주소가 주어진 정렬 단위(alignment)에 맞게 정렬되어 있는지 검사.
→ CUDA 워크스페이스, shared memory, 혹은 allocator 검증 시 유용.

중복 여부:

별도의 중복 없음. (비슷한 기능 없음)

다만 일부 커널 초기화 코드에서 cudaMalloc 정렬 보장 여부를 중복 검증할 수 있음 → 이 함수로 통일 가능.

요약:

워크스페이스 포인터의 정렬 상태를 빠르게 확인하는 공용 유틸.
커널 실행 전 워크스페이스 유효성 검증 단계에서 사용하도록 표준화 가능.