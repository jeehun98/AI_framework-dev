# File: python/graph_executor_v2/graph/graph_exec.py
from __future__ import annotations
from typing import Any, Optional, Sequence
import os
import cupy as cp

from .capture_plan import CapturePlan
from .execution_planner import ExecPlanner, ExecPlan
from .runtime import GraphRuntime  # run_step í•´ì„/ì‹¤í–‰ ë‹´ë‹¹

# Conv2D / WS ìœ í‹¸ (ë¯¸ë˜ í™•ì¥ìš©; í˜„ì¬ íŒŒì¼ ë‚´ ì§ì ‘ ì‚¬ìš© ì•ˆ í•  ìˆ˜ ìˆìŒ)
from graph_executor_v2.layers.conv2d import Conv2D  # noqa: F401
from graph_executor_v2.ops import conv2d as convops  # noqa: F401

# (ì„ íƒ) BN2d íƒ€ì… ê°ì§€ìš©
try:
    from graph_executor_v2.layers.batchnorm import BatchNorm2d as _BN2d  # noqa: F401
except Exception:
    _BN2d = None  # type: ignore

# ===== NVTX (optional) =====
try:
    from graph_executor_v2.backends.cuda.ops.gemm.detail.nvtx_shim import nvtx_range  # type: ignore
except Exception:
    class _DummyNvtx:
        def __call__(self, *_a, **_k):
            class _Ctx:
                def __enter__(self): return None
                def __exit__(self, *args): return False
            return _Ctx()
    nvtx_range = _DummyNvtx()  # type: ignore


class GraphExecLike:
    """CUDA Graph ë¯¸ì‚¬ìš©(ë˜ëŠ” ë¶ˆê°€) í™˜ê²½ì—ì„œì˜ í´ë°± ì‹¤í–‰ì.

    - graphExec(instantiated graph)ì™€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§ì¶˜ë‹¤.
    - ë‚´ë¶€ì— í•œ ìŠ¤í…ì„ ìˆ˜í–‰í•˜ëŠ” í´ë¡œì €(_launch)ë¥¼ ë³´ê´€í•˜ê³  .launch(stream_ptr)ë¡œ í˜¸ì¶œí•œë‹¤.
    """
    def __init__(self, launch_fn, stream: cp.cuda.Stream):
        self._launch = launch_fn
        self._stream = stream

    def launch(self, stream_ptr=None):
        # stream_ptrëŠ” í˜¸í™˜ì„±ìš© ì¸ì(ë¬´ì‹œ). ë‚´ë¶€ì—ì„œ ê³ ì • ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©.
        with self._stream:
            self._launch()


# ---------------- record / instantiate ----------------
def record_step_graph(
    model,
    loss_fn,
    optimizer_step_fn,
    plan: CapturePlan,
    *,
    X_buf: cp.ndarray,
    y_buf: cp.ndarray,
    stream: Optional[cp.cuda.Stream] = None,
    loss_out: Optional[cp.ndarray] = None,          # âœ… ê·¸ë˜í”„ ë‚´ë¶€ì—ì„œ ê°±ì‹ ë  ì†ì‹¤ ìŠ¤ì¹¼ë¼ ë²„í¼(ë””ë°”ì´ìŠ¤, shape=())
    # ---- í™•ì¥ ì¸ì (ë™ì  ê²½ë¡œ/í”Œë˜ë„ˆ) ----
    layers_override: Optional[Sequence[Any]] = None, # ë™ì  ê²½ë¡œ ì „ê°œ ê²°ê³¼(ì—†ìœ¼ë©´ model.layers)
    exec_plan: Optional[ExecPlan] = None,            # Execution Planner ê²°ê³¼
    # ---- ë©”íƒ€/ë””ë²„ê·¸ ----
    graph_key: Optional[Any] = None,                 # GraphPoolì—ì„œ ë§Œë“  í‚¤(ìˆìœ¼ë©´ TrainGraphì— ì „ë‹¬ ê°€ëŠ¥)
    ctx: Optional[dict] = None,                      # ğŸ”¥ NEW: RNG/ë¸Œëœì¹˜ ë“± ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸
):
    """fwd â†’ loss â†’ bwd â†’ opt 'í•œ ìŠ¤í…'ì„ CUDA Graphë¡œ ìº¡ì²˜í•˜ì—¬ ì‹¤í–‰ì ë°˜í™˜.

    ë™ì‘ ê°œìš”:
      1) (ì›Œë°ì—… 1íšŒ) ë™ì¼ ìˆœì„œë¡œ í•œ ë²ˆ ì‹¤í–‰í•˜ì—¬ ë²„í¼/ì›Œí¬ìŠ¤í˜ì´ìŠ¤/ì‹œê·¸ë‹ˆì²˜ë¥¼ ê³ ì •
         - loss_outì´ ì£¼ì–´ì¡Œë‹¤ë©´ ë””ë°”ì´ìŠ¤ ìŠ¤ì¹¼ë¼ë¥¼ ì—¬ê¸°ì— ê¸°ë¡
      2) CUDA Graph ìº¡ì²˜ (ì§€ì› ì‹œ)
         - capture_stream(stream) êµ¬ê°„ ì•ˆì—ì„œ ë™ì¼ ì‹œí€€ìŠ¤ë¥¼ ìˆ˜í–‰
      3) instantiate() í•˜ì—¬ graphExec ë°˜í™˜
      4) CUDA Graph ë¯¸ì§€ì›ì´ë©´ GraphExecLike í´ë°± ë°˜í™˜

    í™•ì¥ í¬ì¸íŠ¸:
      - layers_override: ë™ì  ê²½ë¡œ ì „ê°œ(Sequential._linearize_path)ì˜ ë ˆì´ì–´ ì‹œí€€ìŠ¤ ì§€ì›
      - exec_plan: Execution Planner ê²°ê³¼(ìŠ¤íŠ¸ë¦¼/ì´ë²¤íŠ¸ ìŠ¤ì¼€ì¤„ ë“±)
        â†’ GraphRuntimeê°€ í•´ì„í•˜ì—¬ ì‹¤í–‰ (í˜„ì¬ëŠ” ì„ í˜• ìŠ¤ì¼€ì¤„)

    ì£¼ì˜:
      - BN2d backwardëŠ” X_saved(prev_y) í•„ìš”. ì²« ë ˆì´ì–´ê°€ BNì¸ ê²½ìš° ëŒ€ë¹„í•´
        ëª¨ë¸ ì…ë ¥ ë²„í¼ë¥¼ model._graph_input_bufì— ê¸°ì–µí•´ë‘ .
    """
    if stream is None:
        stream = cp.cuda.Stream(non_blocking=True)

    # ExecPlan ì¤€ë¹„(ì—†ìœ¼ë©´ ê¸°ë³¸ Plannerë¡œ ì„ í˜• ìŠ¤ì¼€ì¤„ ìƒì„±)
    if exec_plan is None:
        exec_plan = ExecPlanner().build(plan=plan, max_streams=1)
    # CapturePlanì— exec_planì„ ì—°ê²°(ëŸ°íƒ€ì„ì—ì„œ ì°¸ì¡°)
    setattr(plan, "exec_plan", exec_plan)

    # ëŸ°íƒ€ì„ ì¤€ë¹„
    rt = GraphRuntime(stream=stream)

    # ğŸ”¥ NEW: RNG ë©”íƒ€ ì£¼ì…(ì»¨í…ìŠ¤íŠ¸ê°€ ì˜¤ë©´ planì— ê³ ì •)
    try:
        rng = (ctx or {}).get("rng", {}) or {}
        if getattr(plan, "seed", None) is None and "seed" in rng:
            setattr(plan, "seed", int(rng["seed"]))
        if getattr(plan, "rng_step", None) is None and "step" in rng:
            setattr(plan, "rng_step", int(rng["step"]))
    except Exception:
        pass

    # ë ˆì´ì–´ ì‹œí€€ìŠ¤ ì„ íƒ(ì •ì : model.layers / ë™ì : layers_override)
    layers_seq: Sequence[Any] = layers_override if layers_override is not None else list(getattr(model, "layers", []))
    assert len(layers_seq) == len(plan.per_layer), \
        f"[record_step_graph] layers vs plan length mismatch: {len(layers_seq)} vs {len(plan.per_layer)}"

    # ------ ì›Œë°ì—… 1íšŒ ------
    with nvtx_range("[CAPTURE] warmup"):
        with stream:
            # BN bwd fallback ëŒ€ë¹„ ì…ë ¥ ë²„í¼ í¬ì¸í„° ë³´ê´€
            setattr(model, "_graph_input_buf", X_buf)
            rt.run_step(
                layers=layers_seq,
                plan=plan,
                loss_fn=loss_fn,
                optimizer_step_fn=optimizer_step_fn,
                X_buf=X_buf,
                y_buf=y_buf,
                loss_out=loss_out,
                capture=False,
            )

    has_graph = hasattr(cp.cuda, "graph") and hasattr(cp.cuda.graph, "capture_stream")

    # ------ CUDA Graph ìº¡ì²˜ ------
    if has_graph:
        with nvtx_range("[CAPTURE] cudaGraphCapture"):
            with stream:
                with cp.cuda.graph.capture_stream(stream) as cap:
                    rt.run_step(
                        layers=layers_seq,
                        plan=plan,
                        loss_fn=loss_fn,
                        optimizer_step_fn=optimizer_step_fn,
                        X_buf=X_buf,
                        y_buf=y_buf,
                        loss_out=loss_out,
                        capture=True,
                    )
        gexec = cap.graph.instantiate()
        return gexec

    # ------ í´ë°± (ê·¸ë˜í”„ ë¯¸ì§€ì›) ------
    def _one_step():
        rt.run_step(
            layers=layers_seq,
            plan=plan,
            loss_fn=loss_fn,
            optimizer_step_fn=optimizer_step_fn,
            X_buf=X_buf,
            y_buf=y_buf,
            loss_out=loss_out,
            capture=False,
        )

    return GraphExecLike(_one_step, stream)


class TrainGraph:
    """ìº¡ì²˜ëœ ê·¸ë˜í”„ ì‹¤í–‰ì + I/O ë²„í¼ ë¬¶ìŒ.

    - set_batch(): í˜¸ìŠ¤íŠ¸/ë‹¤ë¥¸ ë””ë°”ì´ìŠ¤ í…ì„œë¥¼ ê³ ì • I/O ë²„í¼ë¡œ ë³µì‚¬
    - launch(): CUDA Graph ì¸ìŠ¤í„´ìŠ¤(or í´ë°±)ì˜ .launch í˜¸ì¶œ

    ë””ë²„ê·¸ í‘œë©´:
      - í™˜ê²½ë³€ìˆ˜ GEV2_EXPOSE_DEBUG=1 ì¼ ë•Œë§Œ plan/key/tags ë…¸ì¶œ
      - io ë°”ì¸ë”©ì€ ë¬¸ì„œ/í…ŒìŠ¤íŠ¸ í¸ì˜ë¥¼ ìœ„í•´ í•­ìƒ ì½ê¸°ìš©ìœ¼ë¡œ ê³µê°œ
    """
    def __init__(self, gexec, io, stream,
                 *,
                 plan: Optional[CapturePlan] = None,
                 graph_key: Optional[Any] = None,
                 tags: Optional[dict] = None):
        self._gexec = gexec
        self._io = io
        self._stream = stream

        # ë””ë²„ê·¸/ë¬¸ì„œìš© ë…¸ì¶œì€ ê²Œì´íŠ¸ë¡œ ë³´í˜¸
        self._expose_debug = os.getenv("GEV2_EXPOSE_DEBUG", "0") == "1"
        self._plan = plan if self._expose_debug else None
        self._key = graph_key if self._expose_debug else None

        # ğŸ” RNG ë©”íƒ€ë¥¼ íƒœê·¸ì— ë³µì‚¬í•´ íƒ€ì„ë¼ì¸ì—ì„œ ë³´ê¸° ì‰½ê²Œ(ë””ë²„ê·¸ ONì¼ ë•Œë§Œ)
        t = dict(tags or {})
        try:
            if self._plan is not None:
                if getattr(self._plan, "seed", None) is not None:
                    t.setdefault("rng_seed", int(getattr(self._plan, "seed")))
                if getattr(self._plan, "rng_step", None) is not None:
                    t.setdefault("rng_step", int(getattr(self._plan, "rng_step")))
        except Exception:
            pass
        self._tags = t if self._expose_debug else {}

    # ---- ê³µê°œ í‘œë©´(í…ŒìŠ¤íŠ¸/ë¬¸ì„œ í˜¸í™˜) ----
    @property
    def io(self):
        """I/O ë°”ì¸ë”© í…Œì´ë¸”(ë¬¸ì„œÂ·í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„ ìœ„í•´ ê³µê°œ)."""
        return self._io

    @property
    def logits(self):
        return self._io["logits"]

    @property
    def X_buf(self):
        return self._io["X"]

    @property
    def y_buf(self):
        return self._io["y"]

    # ---- ì„ íƒì  ë””ë²„ê·¸ í‘œë©´ ----
    @property
    def plan(self):
        """CapturePlan í•¸ë“¤(í™˜ê²½ë³€ìˆ˜ GEV2_EXPOSE_DEBUG=1ì¼ ë•Œë§Œ ë…¸ì¶œ)."""
        return self._plan

    @property
    def key(self):
        """GraphPool í‚¤(í™˜ê²½ë³€ìˆ˜ GEV2_EXPOSE_DEBUG=1ì¼ ë•Œë§Œ ë…¸ì¶œ)."""
        return self._key

    @property
    def tags(self):
        """NVTX ë“± ìº¡ì²˜/ë¦¬í”Œë ˆì´ íƒœê·¸(í™˜ê²½ë³€ìˆ˜ GEV2_EXPOSE_DEBUG=1ì¼ ë•Œë§Œ ë…¸ì¶œ)."""
        return self._tags

    # pytest/ë¬¸ì„œ ìŠ¤í¬ë¦½íŠ¸ê°€ íƒìƒ‰ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì–‡ì€ í—¬í¼
    def debug_capture_plan(self):
        return self.plan

    def debug_dump_ir(self):
        # IRì€ ë³´í†µ Sequential/Builder ìª½ì—ì„œ ë³´ê´€í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” None ë°˜í™˜
        return None

    def set_batch(self, X_dev, y_dev):
        """í˜„ì¬ ë°°ì¹˜ë¥¼ ê³ ì • I/O ë²„í¼(X/y)ì— ë³µì‚¬ (ê·¸ë˜í”„ì™€ ë™ì¼ ìŠ¤íŠ¸ë¦¼)."""
        xb, yb = self._io["X"], self._io["y"]
        with self._stream:  # âœ… ê·¸ë˜í”„ì™€ ë™ì¼ ìŠ¤íŠ¸ë¦¼ì—ì„œ H2D/D2D ìˆ˜í–‰
            xb[...] = cp.asarray(X_dev, dtype=xb.dtype)
            yb[...] = cp.asarray(y_dev, dtype=yb.dtype)

    def launch(self):
        """CUDA Graph ì¸ìŠ¤í„´ìŠ¤(or í´ë°±) ì‹¤í–‰."""
        self._gexec.launch(self._stream.ptr)
