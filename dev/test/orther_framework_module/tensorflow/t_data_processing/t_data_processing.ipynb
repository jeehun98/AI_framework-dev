{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow에서 데이터 전처리(Data Preprocessing)는 모델 학습의 성능과 정확도를 높이기 위해 중요한 단계입니다. 데이터 전처리는 주로 tf.data, tf.image, tf.keras.preprocessing 등 다양한 모듈을 통해 수행할 수 있습니다. 일반적인 데이터 전처리 과정은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 로드\n",
    "데이터를 로드하는 첫 번째 단계입니다. tf.data.Dataset을 사용해 데이터를 메모리로 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern='data.csv',\n",
    "    batch_size=32,\n",
    "    label_name='target',\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "# 이미지 데이터 로드\n",
    "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'path_to_images',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 정규화 (Normalization)\n",
    "정규화는 입력 데이터의 값을 특정 범위로 조정하는 과정입니다. 일반적으로 이미지 데이터의 경우 [0, 255] 범위의 값을 [0, 1]로 스케일링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "image_dataset = image_dataset.map(normalize_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 데이터 증강 (Data Augmentation)\n",
    "데이터 증강은 모델의 일반화 능력을 높이기 위해 다양한 방식으로 데이터를 변형하는 과정입니다. 이미지를 회전, 반전, 자르기 등을 통해 증강할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.1, upper=0.2)\n",
    "    return image, label\n",
    "\n",
    "image_dataset = image_dataset.map(augment_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 데이터 셔플 (Shuffling)\n",
    "셔플링은 학습 데이터를 무작위로 섞는 과정으로, 모델이 학습 과정에서 데이터의 순서에 영향을 받지 않도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 배치 처리 (Batching)\n",
    "배치 처리는 데이터를 일정한 크기로 묶어 한 번에 여러 샘플을 처리하는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 데이터 캐싱 및 Prefetching\n",
    "캐싱은 데이터를 한 번 로드하고 재사용할 수 있도록 메모리에 저장하는 방법입니다. Prefetching은 데이터 로드와 모델 학습을 동시에 수행할 수 있도록 병렬 처리하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
