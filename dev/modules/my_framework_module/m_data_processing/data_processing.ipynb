{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 8., 9.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치가 있는 행 제거\n",
    "arr_no_nan_rows = arr[~np.isnan(arr).any(axis=1)]\n",
    "arr_no_nan_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 구현 내용, \n",
    "\n",
    "결측치 제거\n",
    "\n",
    "정규화 및 표준화\n",
    "\n",
    "카테고리 데이터 인코딩\n",
    "\n",
    "데이터셋 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class data_processing:\n",
    "    \"\"\"\n",
    "    데이터 전처리 클래스\n",
    "\n",
    "    Methods:\n",
    "        missing_value_del(data, p_axis) : data 의 결측치 행,열 제거\n",
    "    \"\"\"\n",
    "    def missing_value_del(data, p_axis=1):\n",
    "        \"\"\"\n",
    "        결측치가 제거된 데이터 반환\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 결측치가 존재하는 데이터\n",
    "            p_axis(default = 1) : 1 - 결측치 행의 제거, 0 - 결측치 열의 제거\n",
    "\n",
    "        Returns:\n",
    "            결측치가 제거된 ndarray\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # ~ : 결과를 부정, \n",
    "        # np.isnan(data) : NaN 값의 True\n",
    "        # .any : 각 행, 열에 대해 결측치가 하나라도 있으면 True 로 나타낸다.\n",
    "        # data[] : True 값만 남긴다.\n",
    "        return data[~np.isnan(data).any(axis=p_axis)]\n",
    "    \n",
    "    def missing_value_cha(data, is_zero = False, is_ave = False, p_axis = 0):\n",
    "        \"\"\"\n",
    "        결측치의 대체\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 결측치가 존재하는 데이터\n",
    "            is_zero(default = False) : 결측치를 0으로 대체\n",
    "            is_ave(default = False) : 결측치를 평균으로 대체\n",
    "            axis(default = 0) : 평균 대체 시 기준이 되는 열, 행의 선택\n",
    "\n",
    "        Returns:\n",
    "            결측치가 제거된 ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        if(is_zero):\n",
    "            data = np.nan_to_num(data, nan = 0)\n",
    "        \n",
    "        elif(is_ave):\n",
    "            mean = np.nanmean(data, axis = p_axis)\n",
    "            inds = np.where(np.isnan(data))\n",
    "            data[inds] = np.take(mean, inds[0])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def duplicate_data_del(data):\n",
    "        \"\"\"\n",
    "        중복 데이터의 제거\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 중복이 존재하는 데이터\n",
    "\n",
    "        Returns:\n",
    "            중복이 제거된 ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        return np.unique(data, axis=0)\n",
    "    \n",
    "    def min_max_normalization(data):\n",
    "        \"\"\"\n",
    "        min, max 정규화, 데이터를 0과 1 사이의 값으로 변환, \n",
    "        데이터가 특정 범위 내에 존재하도록 보장\n",
    "        값의 범위를 제한해야 하거나, 양수 값만 다루는 경우\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 정규화할 데이터\n",
    "        \n",
    "        Returns:\n",
    "            정규화된 ndarray\n",
    "        \"\"\"\n",
    "        data_min = np.min(data, axis=0)  # 각 열의 최소값\n",
    "        data_max = np.max(data, axis=0)  # 각 열의 최대값\n",
    "        return (data - data_min) / (data_max - data_min)\n",
    "    \n",
    "    def standardize(data):\n",
    "        \"\"\"\n",
    "        표준화, 평균이 0이고 표준편차가 1이 되도록 변환\n",
    "        각 데이터 포인트가 평균에서 몇 표준편차만큼 떨어져 있는지 계산 가능\n",
    "        X' = X - mu / sigma\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            표준화된 ndarray\n",
    "        \"\"\"\n",
    "        data_mean = np.mean(data, axis=0)  # 각 열의 평균\n",
    "        data_std = np.std(data, axis=0)    # 각 열의 표준편차\n",
    "        return (data - data_mean) / data_std\n",
    "    \n",
    "    def max_abs_normalize(data):\n",
    "        \"\"\"\n",
    "        각 특성의 최대 절대값이 1이 되도록 데이터 스케일링 [-1, 1] 범위\n",
    "        데이터에 음수 값이 포함된 경우 유용, 양.음수 관계의 유지\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        data_max_abs = np.max(np.abs(data), axis=0)\n",
    "        return data / data_max_abs\n",
    "    \n",
    "    def robust_normalize(data):\n",
    "        \"\"\"\n",
    "        중앙값과 InterquartileRange, 1분위수와 3분위수 간의 범위)를 사용하여 데이터 정규화\n",
    "        데이터에 이상치가 있을 때, 이상치의 영향을 줄이기 위해 사용\n",
    "        데이터에 이상치가 많을 경우 유용\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray\n",
    "        \"\"\"\n",
    "        data_median = np.median(data, axis=0)\n",
    "        data_iqr = np.percentile(data, 75, axis=0) - np.percentile(data, 25, axis=0)\n",
    "        return (data - data_median) / data_iqr\n",
    "\n",
    "    def unit_vector_normalize(data):\n",
    "        \"\"\"\n",
    "        각 데이터 벡터를 그 벡터의 L2 norm 으로 나누어 벡터의 크기가 1이 되도록 만든다.\n",
    "        데이터를 방향성만 유지하고 크기는 표준화할 때 유용\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray\n",
    "        \"\"\"\n",
    "        norm = np.linalg.norm(data, axis=0)\n",
    "        return data / norm\n",
    "    \n",
    "    def log_normalize(data):\n",
    "        \"\"\"\n",
    "        데이터의  분포가 크게 치우쳐 있는 경우, 로그 변환을 통해 데이터 분포 조정\n",
    "        양수 데이터에만 적용 가능\n",
    "        데이터의 분포가 비대칭적이거나 양수 데이터의 범위가 넓을 때 유용\n",
    "\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray\n",
    "        \"\"\"\n",
    "        return np.log1p(data)\n",
    "    \n",
    "    def one_hot_encoding(data):\n",
    "        \"\"\"\n",
    "        각 카테코리 값을 이진 벡터로 변환하는 방법\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray (p,n)\n",
    "        \"\"\"\n",
    "        # 고유한 카테고리 찾기\n",
    "        unique_categories = np.unique(data)\n",
    "\n",
    "        # 원-핫 인코딩\n",
    "        one_hot_encoded = np.zeros((data.shape[0], unique_categories.shape[0]))\n",
    "\n",
    "        # 각 카테고리 위치에 1 설정\n",
    "        for i, category in enumerate(data):\n",
    "            one_hot_encoded[i, np.where(unique_categories == category)[0][0]] = 1\n",
    "\n",
    "        return one_hot_encoded\n",
    "    \n",
    "    def label_encoding(data):\n",
    "        \"\"\"\n",
    "        각 카테고리 값을 정수로 변환\n",
    "        Args:\n",
    "            data(ndarray) : 데이터\n",
    "        \n",
    "        Returns:\n",
    "            ndarray (p,n)\n",
    "        \"\"\"\n",
    "        # 고유한 카테고리 찾기\n",
    "        unique_categories = np.unique(data)\n",
    "\n",
    "        # 레이블 인코딩\n",
    "        label_encoded = np.array([np.where(unique_categories == category)[0][0] for category in data])\n",
    "\n",
    "        return label_encoded\n",
    "\n",
    "    def shuffle_split_data(train_data, target_data, split_size):\n",
    "        \"\"\"\n",
    "        데이터셋의 분할\n",
    "        Args:\n",
    "            train_data(ndarray) : 훈련 데이터\n",
    "            target_data(ndarray) : 타겟 데이터\n",
    "            split_size : 분할 크기\n",
    "        \n",
    "        Returns:\n",
    "            ndarray1 : 분할 데이터 1\n",
    "            ndarray2 : 분할 데이터 2\n",
    "        \"\"\"\n",
    "        indices = np.arrange(train_data.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # 분할 인덱스 계산\n",
    "        train_size = int(train_data.shape[0] * split_size)\n",
    "        train_indices = indices[:train_size]\n",
    "        test_indices = indices[train_size:]\n",
    "\n",
    "        # 훈련 세트와 테스트 세트로 데이터 분할\n",
    "        X_train, X_test = train_data[train_indices], train_data[test_indices]\n",
    "        y_train, y_test = target_data[train_indices], target_data[test_indices]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
