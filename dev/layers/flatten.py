import numpy as np
import cupy as cp
from dev.layers.layer import Layer

import sys
sys.path.append("C:/Users/owner/Desktop/AI_framework-dev/dev/backend/graph_executor/test")
import graph_executor as ge  # Pybind11 ëª¨ë“ˆ

Shape = ge.Shape
OpExtraParams = ge.OpExtraParams

class Flatten(Layer):
    def __init__(self, input_shape=None, name=None, use_backend_init=False, **kwargs):
        super().__init__(name=name, **kwargs)
        self.input_shape = input_shape
        self.output_shape = None
        self.trainable = False
        self.layer_name = "flatten"
        self.use_backend_init = use_backend_init

        self.name = name or f"flatten_{id(self)}"
        self.output_var = f"{self.name}_out"

    def build(self, input_shape):
        self.input_shape = input_shape
        self.output_shape = self.compute_output_shape(input_shape)
        self.built = True

    def call(self, inputs):
        inputs = cp.asarray(inputs, dtype=cp.float32)

        if inputs.ndim == 1:
            inputs = inputs.reshape(1, -1)
        elif inputs.ndim > 2:
            batch_size = inputs.shape[0]
            flattened_dim = int(np.prod(inputs.shape[1:]))
            inputs = inputs.reshape(batch_size, flattened_dim)

        self.output_shape = inputs.shape

        return inputs

    def __call__(self, x):
        if not self.built:
            self.build(x.shape)
        return self.call(x)

    def backward(self, grad_output):
        return grad_output.reshape(self.input_shape)

    def compute_output_shape(self, input_shape):
        if len(input_shape) < 2:
            raise ValueError(f"Flatten layer expects input shape with rank â‰¥2, got {input_shape}")
        batch = input_shape[0]
        flattened = int(np.prod(input_shape[1:]))
        return (batch, flattened)

    def get_weights(self):
        return []

    def get_config(self):
        base_config = super().get_config()
        config = {
            "class_name": self.__class__.__name__,
            "input_shape": self.input_shape
        }
        return {**base_config, **config}

    @classmethod
    def from_config(cls, config):
        return cls(**config)

    def to_e_matrix(self, input_id):
        if self.input_shape is None:
            raise ValueError("[Flatten] input_shape is None. Did you forget to call build()?")

        if self.output_shape is None:
            self.output_shape = self.compute_output_shape(self.input_shape)

        output_id = self.output_var
        extra = OpExtraParams()

        e_block = [{
            "op_type": 5,  # FLATTEN
            "input_id": input_id,
            "param_id": "",
            "output_id": output_id,
            "extra_params": extra
        }]

        # ğŸ”½ ì…ë ¥ 2D í•´ì„ì„ 'ê·¸ëŒ€ë¡œ' ì‚¬ìš©: (rows_in, cols_in) = (F, H*W) ë˜ëŠ” ì´ì „ ë ˆì´ì–´ì˜ 2D
        # - Conv2Dê°€ ìœ„ì—ì„œ (F, H*W)ë¡œ ë³´ë‚´ë¯€ë¡œ ìë™ìœ¼ë¡œ ë§ìŠµë‹ˆë‹¤.
        # - ë§Œì•½ ì´ì „ ë ˆì´ì–´ê°€ ì´ë¯¸ (1, K)ë¼ë©´ rows_in=1, cols_in=Kê°€ ë©ë‹ˆë‹¤.
        # ì£¼ì˜: self.input_shapeëŠ” ì›ë˜ 4D(NHWC)ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 2D ShapeëŠ” engineì˜ shape_mapì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²Œ ì´ìƒì .
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ, Conv2D ì´í›„ë¼ëŠ” ê°€ì • ì•„ë˜ rows_in/cols_inì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        # ì•ˆì „í•˜ê²Œ í•˜ë ¤ë©´ Sequential.compile ë‹¨ê³„ì—ì„œ shape_mapì„ ì „ë‹¬ë°›ì•„ ì°¸ì¡°í•˜ì„¸ìš”.
        if len(self.input_shape) == 4:
            _, H, W, C = map(int, self.input_shape)
            rows_in, cols_in = int(C), int(H * W)   # âœ… Conv ì •ë ¬ê³¼ ì¼ì¹˜
        else:
            # 2D ì´ì–´ë°›ëŠ” ê²½ìš° ë“±
            rows_in, cols_in = 1, int(np.prod(self.input_shape[1:]))

        rows_out, cols_out = 1, rows_in * cols_in
        shape_map = {
            input_id:  Shape(int(rows_in), int(cols_in)),
            output_id: Shape(int(rows_out), int(cols_out)),
        }
        return e_block, {}, {}, output_id, shape_map