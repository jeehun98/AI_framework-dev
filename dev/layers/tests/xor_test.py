import sys
import os
import ctypes
import numpy as np

import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


# CUDA DLL ëª…ì‹œì  ë¡œë“œ
ctypes.CDLL(r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\bin\cudart64_12.dll")

# Pybind11ë¡œ ë¹Œë“œëœ .pyd ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), "build", "lib.win-amd64-cpython-312"))

# AI framework ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.abspath("C:/Users/owner/Desktop/AI_framework-dev"))
sys.path.append("C:/Users/owner/Desktop/AI_framework-dev/dev/backend/graph_executor/test")

# Pybind11 ëª¨ë“ˆ
import graph_executor as ge

# AI Framework ì„í¬íŠ¸
from dev.models.sequential import Sequential
from dev.layers.dense import Dense
from dev.layers.activation_layer import Activation
from dev.layers.flatten import Flatten


def test_xor_classification_equivalent_to_pytorch():
    print("\n=== [TEST] XOR - Option A (BCE on probs) + Batch Mean ===")

    # ì¬í˜„ì„±
    np.random.seed(42)

    # XOR ì…ë ¥/ì •ë‹µ
    x = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float32)
    y = np.array([[0],[1],[1],[0]], dtype=np.float32)

    # (B, C, H, W) â†’ í”„ë ˆì„ì›Œí¬ì˜ NCHW ê·œì•½ ë§ì¶¤
    x = x.reshape(4, 1, 1, 2)

    # ëª¨ë¸ êµ¬ì„± (Option A): ë§ˆì§€ë§‰ Sigmoid ìœ ì§€, LossëŠ” BCE(prob ê¸°ë°˜)
    model = Sequential(input_shape=(1, 1, 2))
    model.add(Flatten(input_shape=(1, 1, 2)))
    model.add(Dense(units=4, activation=None, initializer="xavier"))   # Linear(2â†’4)
    model.add(Activation("sigmoid"))
    model.add(Dense(units=1, activation=None, initializer="xavier"))   # Linear(4â†’1)
    model.add(Activation("sigmoid"))                                   # Sigmoid

    # ì˜µí‹°ë§ˆì´ì €/ëŸ¬ë‹ë ˆì´íŠ¸: ë°°ì¹˜ í‰ê·  ìŠ¤ì¼€ì¼ì— ë§ì¶° 0.1 ê¶Œì¥
    model.compile(optimizer="sgd", loss="bce", learning_rate=0.1)

    # ê·¸ë˜í”„ í™•ì¸ (ë””ë²„ê·¸ í•„ìš” ì‹œ)
    print("\n=== [Graph E] ê³„ì‚° ê·¸ë˜í”„ ===")
    for i, op in enumerate(model.E):
        print(f"[{i}] type={op.op_type}, input={op.input_id}, output={op.output_id}")
        if op.op_type == 1:
            print(f"[ADD] input={op.input_id} + param={op.param_id} -> output={op.output_id}")

    # í•™ìŠµ ì „Â·í›„ ì†ì‹¤ ë¹„êµ
    print("\n[BEFORE] evaluate on full batch")
    metric_before = model.evaluate(x, y)
    print(f"  BCE(before): {metric_before:.6f}")

    # í•™ìŠµ (ë°°ì¹˜ í‰ê· ì´ ì˜ë„ëŒ€ë¡œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸: batch_size=4)
    model.fit(x, y, epochs=2000, batch_size=4)

    print("\n[AFTER] evaluate on full batch")
    metric_after = model.evaluate(x, y)
    print(f"  BCE(after): {metric_after:.6f}")

    # ì˜ˆì¸¡ ì¶œë ¥
    y_pred = model.predict(x)
    print("\nğŸ” XOR ì˜ˆì¸¡ ê²°ê³¼:")
    print("====================================")
    print("  ì…ë ¥         |  ì •ë‹µ  |  ì˜ˆì¸¡ê°’")
    print("---------------|--------|----------")
    for i in range(len(x)):
        input_vals = x[i].reshape(-1).tolist()
        label_val = y[i][0]
        pred_val = float(y_pred[i][0])
        print(f"  {input_vals}  |   {label_val:.1f}   |  {pred_val:.4f}")
    print("====================================")

if __name__ == "__main__":
    test_xor_classification_equivalent_to_pytorch()
